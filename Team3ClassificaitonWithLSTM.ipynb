{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Team3ClassificaitonWithLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yyao5/CS256_AI/blob/main/Team3ClassificaitonWithLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYVyLRKTONBE"
      },
      "source": [
        "## Milestone 2 Part A \n",
        "#### *(last edited: 6 PM, 11/9/2021)*\n",
        "\n",
        "---\n",
        "\n",
        "The main goal of this milestone is to perform a classification with LSTM on the dataset assigned to your group.\n",
        "\n",
        "The outcome of this milestone is to design, implement, and refine a LSTM machine learning model using Keras' LSTM to predict a given gesture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "380tySmTVmJr"
      },
      "source": [
        "# 0 MEANS TURN GESTURE and 1 MEANS CIRCLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gliu_55hONBK"
      },
      "source": [
        "The following pair of gesture datasets are assigned to \n",
        "\n",
        "(a) Turn left and turn right: Team #4\n",
        "\n",
        "b) Turn  and circle : Team #3\n",
        "\n",
        "c) Stop  and no : Team #2\n",
        "\n",
        "d) Hello  and abort : Team #1\n",
        "\n",
        "### Main tasks\n",
        "1) Prepare the polar angle dataset so that it is ready for Keras LSTM model\n",
        "\n",
        "V1.1) Format and prepare the data and randomly split it into 80% for training and 20% for testing\n",
        "\n",
        "1.2) Prepare your training datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/train \n",
        "\n",
        "1.3) Prepare your testing datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/test \n",
        "\n",
        "2) Create a LSTM model with Keras\n",
        "\n",
        "2.1) Vary the number of LSTM and layers and comment on how this would affect the gesture classification rate\n",
        "\n",
        "2.2) Vary the dropout rate(s) to see how this would affect the gesture classification rate and the CPU time taken to execute the process.\n",
        "\n",
        "3) Repeat (1) - (2) with the polar angular velocity dataset\n",
        "\n",
        "4) Repeat (1) - (2) with both the polar angle and the polar angular velocity datasets\n",
        "\n",
        "5) Comment, with reasons, on (1)-(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQvEHrZFCvYp"
      },
      "source": [
        "**Please provide the online discussion forum info here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikemqyqSu_xQ"
      },
      "source": [
        "# import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxY-BsXTGEUi",
        "outputId": "e304128d-f744-4491-c726-7cb245c8fb51"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq07GxCmLjiH"
      },
      "source": [
        "Everyone must put the copied folder in the exact path shown below so you collaborate and get graded easily.   \n",
        "**No project score will be given for not following this folder configuration**    \n",
        "(Our grader is *not reponsible to figure out your own* perferred Google *folder* configuration)   \n",
        "**Only LSTM using Keras should be used in this milestone**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM2o2IwXIQgY",
        "outputId": "0085f0e2-3af8-4366-dc88-514df7072c14"
      },
      "source": [
        "root_path = \"./drive/My Drive/CS256Project/data/data_for_lstm\"\n",
        "\n",
        "(os.path.exists(root_path)) #Checking if the data paths indeed exist and are valid."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJMH4qG1qqOa"
      },
      "source": [
        "- Import libraries and models needed for this work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJTN-_ZRqqOb"
      },
      "source": [
        "# lstm model\n",
        "# from numpy import mean\n",
        "# from numpy import std\n",
        "# from numpy import dstack\n",
        "# from numpy import load\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# from keras.utils import np_utils\n",
        "from matplotlib import pyplot\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8DlU-uvm-8V"
      },
      "source": [
        "## Prepare your X_train.txt, y_train.txt, X_test.txt, y_test.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkGYkeaEoBVb"
      },
      "source": [
        "## your code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Return a list of numpy objects where each object represents one video \n",
        "def load_files(gesture):\n",
        "  video = []\n",
        "  filenames = os.listdir(os.path.join(\"./drive/My Drive/CS256Project/data/gestures_basic_d2\", gesture))\n",
        "  for filename in filenames:\n",
        "    # print(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'].shape)\n",
        "    video.append(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'])\n",
        "    # break\n",
        "  return video\n",
        "\n",
        "def create_files(filepath):\n",
        "  \n",
        "  dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "  return dataframe.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T60J7CTfPRA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQCOWCG4Xypf"
      },
      "source": [
        "#MIN_JOINT = 5\n",
        "MAX_JOINT = 10\n",
        "MIN_NUM_FRAMES = 72\n",
        "# Move the origin to nose\n",
        "def updateCoord(frame):\n",
        "  return frame - frame[0]\n",
        "\n",
        "\n",
        "def getPolar(frame):\n",
        "  tmp = []\n",
        "  for i in range(1, len(frame)):\n",
        "    tmp.append(np.arctan2(frame[i][1], frame[i][0]))\n",
        "  return tmp\n",
        "\n",
        "\n",
        "def getVolicity(polars):\n",
        "  # deprecated\n",
        "  # the second dimension is 6 since we're just keeping the hand movements, which there will be 6 joints in total\n",
        "  velocity = [[0 for _ in range(MAX_JOINT - MIN_JOINT + 1)] for _ in range(len(polars))]\n",
        "  for frame in range(1, len(polars)):\n",
        "    for joint in range(MAX_JOINT - MIN_JOINT + 1):\n",
        "      velocity[frame][joint] = polars[frame][joint] - polars[frame-1][joint]\n",
        "  return velocity\n",
        "\n",
        "def read_polar(gesture0, gesture1):\n",
        "  X_0_raw = load_files(gesture0)\n",
        "  X_0 = []\n",
        "  for video in X_0_raw:\n",
        "    polar = []\n",
        "    for frame in range(len(video)):\n",
        "      coord = video[frame][1][0].transpose(1, 0)\n",
        "      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n",
        "    velocity = getVolicity(polar)\n",
        "    # print(len(video))\n",
        "    features = np.zeros((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2))\n",
        "    features[:len(video), :, 0] = polar\n",
        "    features[:len(video), :, 1] = velocity\n",
        "    \n",
        "    # for i in range(len(new_coords)):\n",
        "    #   for j in range(6):\n",
        "    #     if(test[i][j][0] != new_coords[i][j] or test[i][j][1] != velocity[i][j]):\n",
        "    #       print(test[0][0])\n",
        "    #       print(new_coords[0][0], velocity[0][0])\n",
        "    # return\n",
        "    X_0.append(features)\n",
        "  y_0 = [0 for _ in range(len(X_0))]\n",
        "\n",
        "  X_1_raw = load_files(gesture1)\n",
        "  X_1 = []\n",
        "  for video in X_1_raw:\n",
        "    polar = []\n",
        "    for frame in range(len(video)):\n",
        "      coord = video[frame][1][0].transpose(1, 0)\n",
        "      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n",
        "    velocity = getVolicity(polar)\n",
        "    # print(len(video))\n",
        "    features = np.zeros((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2))\n",
        "    features[:len(video), :, 0] = polar\n",
        "    features[:len(video), :, 1] = velocity\n",
        "    X_1.append(features)\n",
        "  y_1 = [1 for _ in range(len(X_1))]\n",
        "\n",
        "  return np.array(X_0 + X_1, dtype = object), np.array(y_0 + y_1)\n",
        "\n",
        "# read_polar('turn', 'circle')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6therIGsY5c-"
      },
      "source": [
        "X, y = read_polar('turn', 'circle')\n",
        "# X will be storing m videos, each with n frames, while each frames have 17 joints\n",
        "# y will be an array looking like [[0] * j, [1] * k] where j is the number of first gesture and k will be the number of second gesture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inenKkJxTtPf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# for gesture in ['turn', 'circle']:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KwFdqrbE4WO",
        "outputId": "746d5dbd-8567-4f29-ee92-569a189d4f9e"
      },
      "source": [
        "# X_train.astype('float32')[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.2904196, 0.       ],\n",
              "       [1.1699946, 0.       ],\n",
              "       [2.1399443, 0.       ],\n",
              "       [1.5615909, 0.       ],\n",
              "       [1.8159105, 0.       ],\n",
              "       [1.4803815, 0.       ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXe41jTBXRu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2eacfef-2b52-40c5-cc4c-077de7af00ed"
      },
      "source": [
        "np.array(X_train, dtype=object).shape, np.array(X_test, dtype=object).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((98, 72, 6, 2), (25, 72, 6, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoN8DG9EmyTJ",
        "outputId": "0f46e062-aa62-4a18-c32c-8ca672f04031"
      },
      "source": [
        "len(y_train), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QekNuHagmuHt"
      },
      "source": [
        "- You may modify the code below for you specific project needs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjjgzL7pqqOh"
      },
      "source": [
        "from keras.layers import TimeDistributed\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy, neurons=MIN_NUM_FRAMES):\n",
        "\tverbose, epochs, batch_size = 0, 15, 64\n",
        "\tprint(trainX[:, :, :, 0].shape)\n",
        "\ttrainX = trainX.astype('float32')\n",
        "\ttestX = testX.astype('float32')\n",
        "\tn_timesteps, n_features, n_outputs = MIN_NUM_FRAMES, MAX_JOINT - MAX_JOINT + 1, 2\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(neurons, input_length=trainX.shape[1], input_dim=trainX.shape[2]))\n",
        "  # model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "\t# fit network\n",
        "\tmodel.summary()\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tmodel.fit(trainX[:, :, :, 0], trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# model.fit(trainX, trainy)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX[:, :, :, 0], testy, batch_size=batch_size, verbose=verbose)\n",
        "\treturn accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtinWT4hlzm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ea5d67-fa40-4450-d8c8-aa285058d1ef"
      },
      "source": [
        "evaluate_model(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(98, 72, 6)\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_33 (LSTM)              (None, 72)                22752     \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 72)                0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 100)               7300      \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,254\n",
            "Trainable params: 30,254\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.800000011920929"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMleT0EZqqOi"
      },
      "source": [
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOjMClifqqOk"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment(max_lstm=1001):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy = load_dataset(prefix=root_path)\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(100,max_lstm,100):\n",
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy,max_lstm)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('> with %d LSTMs: %.3f' % (r, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB8dOoqIqqOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e051cec-9069-49b4-bf54-5f65dc90c570"
      },
      "source": [
        "%%time\n",
        "# run the experiment\n",
        "run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filenames: ['total_acc_x_train.txt', 'total_acc_y_train.txt', 'total_acc_z_train.txt', 'body_acc_x_train.txt', 'body_acc_y_train.txt', 'body_acc_z_train.txt', 'body_gyro_x_train.txt', 'body_gyro_y_train.txt', 'body_gyro_z_train.txt']\n",
            "(7352, 128, 9) (7352, 1)\n",
            "filenames: ['total_acc_x_test.txt', 'total_acc_y_test.txt', 'total_acc_z_test.txt', 'body_acc_x_test.txt', 'body_acc_y_test.txt', 'body_acc_z_test.txt', 'body_gyro_x_test.txt', 'body_gyro_y_test.txt', 'body_gyro_z_test.txt']\n",
            "(2947, 128, 9) (2947, 1)\n",
            "[samples, time steps, features] (7352, 128, 9) (7352, 6) [samples, time steps, features] (2947, 128, 9) (2947, 6)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 1001)              4048044   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1001)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               100200    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,148,850\n",
            "Trainable params: 4,148,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnkLeNbKqqOg"
      },
      "source": [
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint('[samples, time steps, features]',trainX.shape, trainy.shape, '[samples, time steps, features]',testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpKBzaIQvUok"
      },
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuweGs6HqqOf"
      },
      "source": [
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7ed6n3AqqOf"
      },
      "source": [
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\tprint('filenames:', filenames)\n",
        "  # print('filenames shape:', filenames.shape)\n",
        "\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}